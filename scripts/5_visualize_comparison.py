import sys
import os
import cv2
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torchvision import transforms
from tqdm import tqdm

# å¼•å…¥ Captum ç»„ä»¶
from captum.attr import LayerGradCam, IntegratedGradients, NoiseTunnel

# --- è·¯å¾„é€‚é… ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.append(project_root)

from src.config import Config
from src.dataset import RSNADataset
from src.model import get_model
from src.xai_engine import AdvancedXAIEngine


# =========================================================================
# ğŸ› ï¸ ä¿®å¤ç‰ˆXAIå¼•æ“ (è§£å†³å…¼å®¹æ€§é—®é¢˜)
# =========================================================================
class FixedXAIEngine(AdvancedXAIEngine):
    """ä¿®å¤ç‰ˆè§£é‡Šå¼•æ“ï¼šè§£å†³Grad-CAMåˆå§‹åŒ–æŠ¥é”™åŠSwinç»´åº¦ä¸åŒ¹é…é—®é¢˜"""

    def __init__(self, model, device, model_name=None):
        self.model = model.eval()  # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
        self.device = device
        self.model_name = model_name or getattr(model, 'model_name', 'unknown')

        # è‡ªåŠ¨é€‰æ‹©é€‚åˆçš„ç›®æ ‡å±‚
        self.target_layer = self._select_target_layer_safe()

        # åˆå§‹åŒ–è§£é‡Šå™¨ï¼ˆç§»é™¤reshape_transformå‚æ•°ï¼‰
        self.grad_cam = self._init_grad_cam()
        self.ig = IntegratedGradients(model)
        self.nt = NoiseTunnel(self.ig)  # ç”¨äºç”ŸæˆSmoothGrad

    def _select_target_layer_safe(self):
        """ä¸ºä¸åŒæ¨¡å‹é€‰æ‹©åˆé€‚çš„ç‰¹å¾å±‚"""
        if 'densenet' in self.model_name:
            return self.model.features.denseblock4.denselayer16.conv2
        elif 'swin' in self.model_name:
            return self.model.features[-1][-1].norm1
        else:
            return list(self.model.children())[-1]

    def _init_grad_cam(self):
        """å®‰å…¨åˆå§‹åŒ–Grad-CAM"""
        try:
            return LayerGradCam(self.model, self.target_layer)
        except Exception as e:
            print(f"âŒ Grad-CAMåˆå§‹åŒ–å¤±è´¥ï¼ˆæ¨¡å‹{self.model_name}ï¼‰: {str(e)}")
            return None

    def _generate_single_pass(self, input_tensor, method='gradcam'):
        """ç”Ÿæˆå•å¼ è§£é‡Šçƒ­åŠ›å›¾"""
        input_tensor = input_tensor.to(self.device).requires_grad_(True)

        if method == 'gradcam':
            if not self.grad_cam: return np.zeros(input_tensor.shape[2:])
            try:
                attr = self.grad_cam.attribute(input_tensor, relu_attributions=True)
                # Swinç‰¹å¾å›¾ç»´åº¦é€‚é…
                if 'swin' in self.model_name and attr.dim() == 4:
                    if attr.shape[-1] > attr.shape[1]:
                        attr = attr.permute(0, 3, 1, 2)

                attr = LayerGradCam.interpolate(attr, (input_tensor.shape[2], input_tensor.shape[3]),
                                                interpolate_mode='bilinear')
                heatmap = attr.detach().cpu().numpy()[0, 0]
            except Exception as e:
                # print(f"âš ï¸ Grad-CAMè®¡ç®—è­¦å‘Š: {str(e)}") # å‡å°‘åˆ·å±
                heatmap = np.zeros((input_tensor.shape[2], input_tensor.shape[3]))

        elif method == 'ig':
            try:
                # ä¼˜å…ˆä½¿ç”¨SmoothGrad
                attr = self.nt.attribute(input_tensor, nt_type='smoothgrad', nt_samples=3, target=0)
            except:
                # å›é€€
                attr = self.ig.attribute(input_tensor, n_steps=10, target=0)
            heatmap = np.sum(np.abs(attr.detach().cpu().numpy()[0]), axis=0)
        else:
            heatmap = np.zeros((input_tensor.shape[2], input_tensor.shape[3]))

        # å½’ä¸€åŒ–
        min_v, max_v = heatmap.min(), heatmap.max()
        if max_v - min_v > 1e-8:
            return (heatmap - min_v) / (max_v - min_v)
        return np.zeros_like(heatmap)

    def generate(self, input_tensor, method='gradcam'):
        self.model.eval()
        return self._generate_single_pass(input_tensor, method)

    def generate_bayesian(self, input_tensor, method='gradcam', num_samples=10):
        """è’™ç‰¹å¡æ´›Dropoutä¸ç¡®å®šæ€§"""
        for m in self.model.modules():
            if m.__class__.__name__.startswith('Dropout'): m.train()

        heatmaps = [self._generate_single_pass(input_tensor, method) for _ in range(num_samples)]

        self.model.eval()
        heatmaps = np.array(heatmaps)
        mean_map = np.mean(heatmaps, axis=0)
        std_map = np.std(heatmaps, axis=0)

        if mean_map.max() > 0:
            mean_map = (mean_map - mean_map.min()) / (mean_map.max() - mean_map.min())

        return mean_map, std_map


# =========================================================================
# è¾…åŠ©å‡½æ•°
# =========================================================================
def overlay_heatmap(img_rgb, heatmap):
    """å åŠ çƒ­åŠ›å›¾ï¼ˆå¢å¼ºé²æ£’æ€§ï¼‰"""
    # 1. å¤„ç†NaNå’ŒInf
    heatmap = np.nan_to_num(heatmap, nan=0.0, posinf=1.0, neginf=0.0)
    # 2. ç¡®ä¿èŒƒå›´
    heatmap = np.clip(heatmap, 0, 1)

    heatmap_uint8 = np.uint8(255 * heatmap)
    heatmap_rgb = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
    heatmap_rgb = cv2.cvtColor(heatmap_rgb, cv2.COLOR_BGR2RGB)

    return cv2.addWeighted(img_rgb, 0.7, heatmap_rgb, 0.3, 0)


def load_checkpoint_smart(model, path, model_name):
    """æ™ºèƒ½åŠ è½½æƒé‡"""
    if not os.path.exists(path):
        print(f"âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return False

    print(f"ğŸ“‚ åŠ è½½æƒé‡: {path}")
    try:
        state_dict = torch.load(path, map_location=Config.DEVICE)
        new_state_dict = {}

        for k, v in state_dict.items():
            k = k.replace('module.', '')
            # DenseNeté€‚é…
            if model_name == 'densenet121' and 'classifier' in k:
                k = k.replace('classifier.0', 'classifier.1')
                k = k.replace('classifier.weight', 'classifier.1.weight')
                k = k.replace('classifier.bias', 'classifier.1.bias')
            # Swiné€‚é…
            elif model_name == 'swin_t' and 'head' in k:
                k = k.replace('head.weight', 'head.1.weight')
                k = k.replace('head.bias', 'head.1.bias')
                k = k.replace('head.0', 'head.1')
            new_state_dict[k] = v

        model.load_state_dict(new_state_dict, strict=False)
        print("âœ… æƒé‡åŠ è½½æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {str(e)}")
        return False


# =========================================================================
# ä¸»å¯è§†åŒ–å‡½æ•°
# =========================================================================
def visualize_comparison():
    print("ğŸ¨ åˆå§‹åŒ–å¯è§†åŒ–å·¥å…·...")
    device = Config.DEVICE

    # æ–‡ä»¶å¤¹è·¯å¾„è®¾ç½®
    save_dir = os.path.join(Config.OUTPUT_DIR, 'figures_final_5')
    os.makedirs(save_dir, exist_ok=True)
    print(f"ğŸ“‚ ç»“æœå°†ä¿å­˜è‡³: {save_dir}")

    # 1. åŠ è½½æ¨¡å‹
    print("\nğŸ“Œ åŠ è½½æ¨¡å‹ä¸­...")
    model_dense = get_model('densenet121', pretrained=False, mc_dropout=True)
    if not load_checkpoint_smart(model_dense,
                                 os.path.join(Config.OUTPUT_DIR, 'checkpoints', 'best_model_densenet121.pth'),
                                 'densenet121'): return
    model_dense.to(device)

    model_swin = get_model('swin_t', pretrained=False, mc_dropout=True)
    if not load_checkpoint_smart(model_swin, os.path.join(Config.OUTPUT_DIR, 'checkpoints', 'best_model_swin_t.pth'),
                                 'swin_t'): return
    model_swin.to(device)

    # 2. åˆå§‹åŒ–å¼•æ“
    print("\nğŸ”§ åˆå§‹åŒ–è§£é‡Šå¼•æ“...")
    xai_dense = FixedXAIEngine(model_dense, device, 'densenet121')
    xai_swin = FixedXAIEngine(model_swin, device, 'swin_t')

    # 3. åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
    try:
        ds = RSNADataset(
            os.path.join(Config.PROCESSED_DIR, 'test.csv'),
            Config.RAW_IMG_DIR,
            transform=transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            mode='eval',
            full_df_path=Config.RAW_LABEL_CSV
        )
    except Exception as e:
        print(f"âŒ æ•°æ®é›†é”™è¯¯: {e}")
        return

    # 4. æé€Ÿç­›é€‰
    print("\nâš¡ ç­›é€‰é˜³æ€§æ ·æœ¬...")
    try:
        if 'Target' in ds.data.columns:
            positive_indices = ds.data[ds.data['Target'] == 1].index.tolist()
        else:
            print("âš ï¸ æ…¢é€Ÿç­›é€‰æ¨¡å¼ (æ— Targetåˆ—)")
            positive_indices = [i for i in range(len(ds)) if ds[i][1] == 1]

        if not positive_indices:
            print("âŒ æ— é˜³æ€§æ ·æœ¬")
            return

        vis_count = min(3, len(positive_indices))
        indices = positive_indices[:vis_count]
        print(f"âœ… å‡†å¤‡å¯è§†åŒ–å‰ {vis_count} ä¸ªæ ·æœ¬")

    except Exception as e:
        print(f"âŒ ç­›é€‰å¤±è´¥: {e}")
        return

    # 5. ç»˜å›¾
    fig, axes = plt.subplots(nrows=len(indices), ncols=6, figsize=(24, 5 * len(indices)))
    if len(indices) == 1: axes = np.array([axes])

    print("\nğŸ–¼ï¸ å¼€å§‹ç”Ÿæˆå›¾åƒ...")
    for row_idx, data_idx in enumerate(tqdm(indices)):
        try:
            img_tensor, target, gt_mask, pid = ds[data_idx]
            img_input = img_tensor.unsqueeze(0)

            # åå½’ä¸€åŒ–
            img_vis = img_tensor.permute(1, 2, 0).numpy()
            img_vis = (img_vis * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])
            img_vis = np.clip(img_vis, 0, 1)
            img_vis_uint8 = (img_vis * 255).astype(np.uint8)

            # GT
            img_gt = img_vis_uint8.copy()
            if gt_mask.sum() > 0:
                contours, _ = cv2.findContours(gt_mask.numpy().astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(img_gt, contours, -1, (255, 0, 0), 2)

            # ç”Ÿæˆè§£é‡Š
            gc_dense = xai_dense.generate(img_input, 'gradcam')
            ig_dense = xai_dense.generate(img_input, 'ig')
            gc_swin = xai_swin.generate(img_input, 'gradcam')
            ig_swin = xai_swin.generate(img_input, 'ig')
            _, std_swin = xai_swin.generate_bayesian(img_input, 'gradcam', 10)

            titles = [
                f"Patient {pid}\nGround Truth", "DenseNet\nGrad-CAM", "DenseNet\nSmoothGrad (IG)",
                "Swin\nGrad-CAM", "Swin\nSmoothGrad (IG)", "Swin\nUncertainty Map"
            ]
            images = [
                img_gt, overlay_heatmap(img_vis_uint8, gc_dense), overlay_heatmap(img_vis_uint8, ig_dense),
                overlay_heatmap(img_vis_uint8, gc_swin), overlay_heatmap(img_vis_uint8, ig_swin), std_swin
            ]

            # å­å›¾ç»˜åˆ¶
            for col_idx, (img, title) in enumerate(zip(images, titles)):
                ax = axes[row_idx][col_idx]
                if col_idx == 5:  # Uncertainty
                    if img.max() > 0: img = img / img.max()
                    im = ax.imshow(img, cmap='inferno')
                else:
                    ax.imshow(img)

                ax.set_title(title, fontsize=12, fontweight='bold' if col_idx == 0 else 'normal')
                ax.axis('off')

            # [ä¼˜åŒ–] æ¯æ¬¡å¾ªç¯åæ¸…ç†æ˜¾å­˜ï¼Œé˜²æ­¢OOM
            torch.cuda.empty_cache()

        except Exception as e:
            print(f"âš ï¸ æ ·æœ¬ {pid} å‡ºé”™: {e}")
            continue

    plt.subplots_adjust(wspace=0.05, hspace=0.15)
    # [ä¼˜åŒ–] æ·»åŠ æ€»æ ‡é¢˜
    plt.suptitle(f"Comparative XAI Visualization: DenseNet vs Swin Transformer (Top {len(indices)} Samples)",
                 fontsize=16, y=0.98)

    save_path = os.path.join(save_dir, 'advanced_comparison_grid.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"\nğŸ‰ ç»“æœå·²ä¿å­˜: {save_path}")


if __name__ == "__main__":
    visualize_comparison()